{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e678b758-8577-4398-a204-b41b29738a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 01:35:07.223809: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-28 01:35:07.266054: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-28 01:35:07.266089: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-28 01:35:07.267021: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-28 01:35:07.272769: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-28 01:35:07.273166: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-28 01:35:08.111138: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16c50523-59f7-4954-abff-1f6d03cfecfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('bees-wasps.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69c1b96a-e8ee-421e-84c9-635882ad6218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpzvj8dd9b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpzvj8dd9b/assets\n",
      "2023-11-28 01:35:10.922780: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2023-11-28 01:35:10.922811: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2023-11-28 01:35:10.923465: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpzvj8dd9b\n",
      "2023-11-28 01:35:10.924550: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2023-11-28 01:35:10.924563: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpzvj8dd9b\n",
      "2023-11-28 01:35:10.926367: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2023-11-28 01:35:10.927062: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2023-11-28 01:35:11.048036: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpzvj8dd9b\n",
      "2023-11-28 01:35:11.075887: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 152423 microseconds.\n",
      "2023-11-28 01:35:11.113199: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 7, Total Ops 16, % non-converted = 43.75 %\n",
      " * 7 ARITH ops\n",
      "\n",
      "- arith.constant:    7 occurrences  (f32: 6, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 1)\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('bees-wasps.tflite', 'wb') as f_out:\n",
    "    f_out.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6464c385-542c-430b-a0e5-126d52feccef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 129M\n",
      "-rw-rw-r-- 1 paul paul  86M Nov 27 22:15 bees-wasps.h5\n",
      "-rw-rw-r-- 1 paul paul  43M Nov 28 01:35 bees-wasps.tflite\n",
      "-rw-rw-r-- 1 paul paul 416K Nov 27 23:12 corto.jpeg\n",
      "drwxrwxr-x 2 paul paul 4,0K Nov 27 23:11 data\n",
      "-rw-rw-r-- 1 paul paul  264 Nov 28 00:33 Dockerfile\n",
      "-rw-rw-r-- 1 paul paul  19K Nov 28 01:33 h9.ipynb\n",
      "-rw-rw-r-- 1 paul paul 1,4K Nov 28 00:37 lambda_function.py\n"
     ]
    }
   ],
   "source": [
    "!ls -lh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943c50f4-1ae3-4bef-b522-fcb2ab50e91a",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "### The size is: 43Mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c88f4d5b-4850-4d70-931c-664702cd2228",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.lite as tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1902382-9331-4ad2-9d41-f1a02d855dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "interpreter = tflite.Interpreter(model_path='bees-wasps.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_index = interpreter.get_input_details()[0]['index']\n",
    "output_index = interpreter.get_output_details()[0]['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "160a7987-6a8c-4c2f-876b-1ccd4ce4e831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b89a65-40bd-4809-addf-d61397c284ab",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "### The ouput index for this model is 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dc3288a-eca7-4adb-b197-631d3278306f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from urllib import request\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "def download_image(url):\n",
    "    with request.urlopen(url) as resp:\n",
    "        buffer = resp.read()\n",
    "    stream = BytesIO(buffer)\n",
    "    img = Image.open(stream)\n",
    "    return img\n",
    "\n",
    "\n",
    "def prepare_image(img, target_size):\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    img = img.resize(target_size, Image.NEAREST)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "674017c4-c81f-4b1a-8fac-2fc2cdec9813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in /home/paul/anaconda3/lib/python3.11/site-packages (10.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cad4b277-64f5-4364-bffb-c6db823ac26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_image_helper import create_preprocessor\n",
    "from tensorflow.keras.applications.xception import preprocess_input\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45b1dfab-ee72-4af6-bfba-3fd91ebab2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ea4b192-52f8-4748-b1c7-384847256f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 150, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[[0.9450981 , 0.9058824 , 0.8588236 ],\n",
       "         [0.93725497, 0.9215687 , 0.97647065],\n",
       "         [0.91372555, 0.8980393 , 0.9568628 ],\n",
       "         ...,\n",
       "         [0.2901961 , 0.33333334, 0.16470589],\n",
       "         [0.34901962, 0.40784317, 0.15294118],\n",
       "         [0.29803923, 0.36078432, 0.11764707]],\n",
       "\n",
       "        [[0.9490197 , 0.909804  , 0.8705883 ],\n",
       "         [0.9176471 , 0.909804  , 0.9607844 ],\n",
       "         [0.90196085, 0.8941177 , 0.9490197 ],\n",
       "         ...,\n",
       "         [0.27450982, 0.3372549 , 0.16078432],\n",
       "         [0.47058827, 0.5058824 , 0.18823531],\n",
       "         [0.45098042, 0.49411768, 0.18431373]],\n",
       "\n",
       "        [[0.9294118 , 0.882353  , 0.8196079 ],\n",
       "         [0.91372555, 0.909804  , 0.96470594],\n",
       "         [0.9058824 , 0.8941177 , 0.9607844 ],\n",
       "         ...,\n",
       "         [0.32156864, 0.37647063, 0.1764706 ],\n",
       "         [0.5058824 , 0.5254902 , 0.20392159],\n",
       "         [0.43137258, 0.4666667 , 0.20392159]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.03137255, 0.06666667, 0.04705883],\n",
       "         [0.02352941, 0.08627451, 0.04705883],\n",
       "         [0.08235294, 0.08235294, 0.09019608],\n",
       "         ...,\n",
       "         [0.4431373 , 0.36078432, 0.0509804 ],\n",
       "         [0.16862746, 0.1764706 , 0.12156864],\n",
       "         [0.1254902 , 0.15686275, 0.1137255 ]],\n",
       "\n",
       "        [[0.03137255, 0.06666667, 0.04705883],\n",
       "         [0.07843138, 0.11764707, 0.08627451],\n",
       "         [0.05490196, 0.09803922, 0.07450981],\n",
       "         ...,\n",
       "         [0.32156864, 0.26666668, 0.07450981],\n",
       "         [0.12156864, 0.13333334, 0.10588236],\n",
       "         [0.09411766, 0.1137255 , 0.09019608]],\n",
       "\n",
       "        [[0.01960784, 0.03921569, 0.02352941],\n",
       "         [0.08627451, 0.1137255 , 0.08235294],\n",
       "         [0.10196079, 0.12156864, 0.09411766],\n",
       "         ...,\n",
       "         [0.16470589, 0.1764706 , 0.10980393],\n",
       "         [0.13333334, 0.15686275, 0.11764707],\n",
       "         [0.09803922, 0.11764707, 0.09019608]]]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "img = download_image('https://habrastorage.org/webt/rt/d9/dh/rtd9dhsmhwrdezeldzoqgijdg8a.jpeg')\n",
    "x = prepare_image(img, (150,150))\n",
    "x = np.asarray(x)\n",
    "print(x.shape)\n",
    "x = x.reshape((1,) + x.shape)\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "x = datagen.flow(x)\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c53bda-a2ee-4ea7-8016-60af13d7f5bf",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "### Value in the first pixel, the R channel is 0.9450980"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd09c27f-d9d4-4fac-ac9f-3a2dae7b2028",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow.lite as tflite\n",
    "from keras_image_helper import create_preprocessor\n",
    "\n",
    "interpreter = tflite.Interpreter(model_path='bees-wasps.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_index = interpreter.get_input_details()[0]['index']\n",
    "output_index = interpreter.get_output_details()[0]['index']\n",
    "\n",
    "interpreter.set_tensor(input_index, x[0])\n",
    "interpreter.invoke()\n",
    "preds = interpreter.get_tensor(output_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a225fb73-6d51-41a1-8904-ff29a60059a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 150, 150, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd61e93e-6889-4985-abeb-da7ae11b4998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6589842]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184a5d2a-59a8-42ea-b17e-a82b1a91dad3",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "### The output of the model is 0.65898"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84de81cf-6261-449f-a495-c89c9f6828d8",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "### The size of the base image from agrigorev/zoomcamp-bees-wasps:v2 is 662Mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cab54789-617e-4d95-a86a-4a0e4b1efdbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6589841842651367]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tflite_runtime.interpreter as tflite\n",
    "from keras_image_helper import create_preprocessor\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def load_img(url, target_size=(150,150), rescale=1./255):\n",
    "    img = download_image(url)\n",
    "    x = prepare_image(img, (150,150))\n",
    "    x = np.asarray(x,dtype=np.float32)\n",
    "    x = x.reshape((1,) + x.shape)\n",
    "    x = x*rescale\n",
    "    return x\n",
    "\n",
    "interpreter = tflite.Interpreter(model_path='bees-wasps.tflite')\n",
    "input_index = interpreter.get_input_details()[0]['index']\n",
    "output_index = interpreter.get_output_details()[0]['index']\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "def predict(url):\n",
    "    x=load_img(url)\n",
    "    interpreter.set_tensor(input_index, x)\n",
    "    interpreter.invoke()\n",
    "    preds = interpreter.get_tensor(output_index)\n",
    "    float_predictions = preds[0].tolist()\n",
    "    return float_predictions\n",
    "\n",
    "url='https://habrastorage.org/webt/rt/d9/dh/rtd9dhsmhwrdezeldzoqgijdg8a.jpeg'\n",
    "predict(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618fa1d2-57dc-4ffd-a635-d2decb056a14",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "### Using the alternative model we get an output of 0.4453"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4d5171-c823-4df4-a0b1-7c187028522c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
